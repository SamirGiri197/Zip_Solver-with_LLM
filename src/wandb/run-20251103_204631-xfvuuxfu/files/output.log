2025-11-03 20:46:36,269 - llm_manager - INFO - wandb initialized successfully
2025-11-03 20:46:36,271 - metrics - INFO - Game metrics started for 8x8 board
2025-11-03 20:46:36,271 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:46:36,272 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:46:36,272 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:46:39,532 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:46:39,534 - llm_manager - INFO - Ollama response length: 216 chars
2025-11-03 20:46:39,538 - llm_manager - INFO - Parsed move: (1, 2)
2025-11-03 20:46:39,538 - metrics - INFO - Move 1: (1, 2) - Valid: True, Latency: 3267ms, Confidence: 0.90
2025-11-03 20:46:39,540 - GUI - INFO - Move 1: (1, 2) - Valid
2025-11-03 20:46:40,534 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:46:40,535 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:46:40,536 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:46:44,052 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:46:44,055 - llm_manager - INFO - Ollama response length: 245 chars
2025-11-03 20:46:44,061 - llm_manager - INFO - Parsed move: (2, 2)
2025-11-03 20:46:44,061 - metrics - INFO - Move 2: (2, 2) - Valid: True, Latency: 3527ms, Confidence: 0.90
2025-11-03 20:46:44,062 - GUI - INFO - Move 2: (2, 2) - Valid
2025-11-03 20:46:45,057 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:46:45,058 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:46:45,059 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:46:50,407 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:46:50,409 - llm_manager - INFO - Ollama response length: 258 chars
2025-11-03 20:46:50,411 - llm_manager - INFO - Parsed move: (3, 2)
2025-11-03 20:46:50,412 - metrics - INFO - Move 3: (3, 2) - Valid: True, Latency: 5354ms, Confidence: 0.90
2025-11-03 20:46:50,412 - GUI - INFO - Move 3: (3, 2) - Valid
2025-11-03 20:46:51,404 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:46:51,405 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:46:51,406 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:46:55,723 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:46:55,725 - llm_manager - INFO - Ollama response length: 263 chars
2025-11-03 20:46:55,727 - llm_manager - INFO - Parsed move: (3, 3)
2025-11-03 20:46:55,727 - metrics - INFO - Move 4: (3, 3) - Valid: True, Latency: 4322ms, Confidence: 0.90
2025-11-03 20:46:55,728 - GUI - INFO - Move 4: (3, 3) - Valid
2025-11-03 20:46:56,737 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:46:56,738 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:46:56,739 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:47:00,173 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:47:00,174 - llm_manager - INFO - Ollama response length: 258 chars
2025-11-03 20:47:00,175 - llm_manager - INFO - Parsed move: (3, 4)
2025-11-03 20:47:00,175 - metrics - INFO - Move 5: (3, 4) - Valid: True, Latency: 3438ms, Confidence: 0.90
2025-11-03 20:47:00,176 - GUI - INFO - Move 5: (3, 4) - Valid
2025-11-03 20:47:01,171 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:47:01,172 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:47:01,172 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:47:04,065 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:47:04,065 - llm_manager - INFO - Ollama response length: 230 chars
2025-11-03 20:47:04,067 - llm_manager - INFO - Parsed move: (4, 4)
2025-11-03 20:47:04,068 - metrics - INFO - Move 6: (4, 4) - Valid: True, Latency: 2896ms, Confidence: 0.90
2025-11-03 20:47:04,068 - GUI - INFO - Move 6: (4, 4) - Valid
2025-11-03 20:47:05,067 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:47:05,069 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:47:05,070 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:47:07,415 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:47:07,419 - llm_manager - INFO - Ollama response length: 227 chars
2025-11-03 20:47:07,420 - llm_manager - INFO - Parsed move: (5, 4)
2025-11-03 20:47:07,421 - metrics - INFO - Move 7: (5, 4) - Valid: True, Latency: 2352ms, Confidence: 0.90
2025-11-03 20:47:07,422 - GUI - INFO - Move 7: (5, 4) - Valid
2025-11-03 20:47:08,420 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:47:08,420 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:47:08,421 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:47:12,162 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:47:12,163 - llm_manager - INFO - Ollama response length: 285 chars
2025-11-03 20:47:12,164 - llm_manager - INFO - Parsed move: (5, 5)
2025-11-03 20:47:12,165 - metrics - INFO - Move 8: (5, 5) - Valid: True, Latency: 3745ms, Confidence: 0.90
2025-11-03 20:47:12,165 - GUI - INFO - Move 8: (5, 5) - Valid
2025-11-03 20:47:13,171 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:47:13,172 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:47:13,173 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:47:17,320 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:47:17,322 - llm_manager - INFO - Ollama response length: 225 chars
2025-11-03 20:47:17,322 - llm_manager - INFO - Parsed move: (5, 6)
2025-11-03 20:47:17,322 - metrics - INFO - Move 9: (5, 6) - Valid: True, Latency: 4150ms, Confidence: 0.90
2025-11-03 20:47:17,323 - GUI - INFO - Move 9: (5, 6) - Valid
2025-11-03 20:47:18,329 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:47:18,330 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:47:18,330 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:47:21,923 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:47:21,924 - llm_manager - INFO - Ollama response length: 263 chars
2025-11-03 20:47:21,924 - llm_manager - INFO - Parsed move: (5, 7)
2025-11-03 20:47:21,926 - metrics - INFO - Move 10: (5, 7) - Valid: True, Latency: 3596ms, Confidence: 0.90
2025-11-03 20:47:21,926 - GUI - INFO - Move 10: (5, 7) - Valid
2025-11-03 20:47:22,932 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:47:22,932 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:47:22,938 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:47:27,823 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:47:27,825 - llm_manager - INFO - Ollama response length: 277 chars
2025-11-03 20:47:27,833 - llm_manager - INFO - Parsed move: (6, 7)
2025-11-03 20:47:27,833 - metrics - INFO - Move 11: (6, 7) - Valid: True, Latency: 4901ms, Confidence: 0.90
2025-11-03 20:47:27,834 - GUI - INFO - Move 11: (6, 7) - Valid
2025-11-03 20:47:28,843 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:47:28,843 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:47:28,844 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:47:32,559 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:47:32,559 - llm_manager - INFO - Ollama response length: 223 chars
2025-11-03 20:47:32,561 - llm_manager - INFO - Parsed move: (7, 7)
2025-11-03 20:47:32,561 - metrics - INFO - Move 12: (7, 7) - Valid: True, Latency: 3717ms, Confidence: 0.90
2025-11-03 20:47:32,561 - GUI - INFO - Move 12: (7, 7) - Valid
2025-11-03 20:47:33,576 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:47:33,577 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:47:33,578 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:47:36,143 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:47:36,144 - llm_manager - INFO - Ollama response length: 212 chars
2025-11-03 20:47:36,145 - llm_manager - INFO - Parsed move: (7, 6)
2025-11-03 20:47:36,145 - metrics - INFO - Move 13: (7, 6) - Valid: True, Latency: 2569ms, Confidence: 0.90
2025-11-03 20:47:36,145 - GUI - INFO - Move 13: (7, 6) - Valid
2025-11-03 20:47:37,151 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:47:37,151 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:47:37,152 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:47:40,679 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:47:40,682 - llm_manager - INFO - Ollama response length: 220 chars
2025-11-03 20:47:40,683 - llm_manager - INFO - Parsed move: (6, 6)
2025-11-03 20:47:40,684 - metrics - INFO - Move 14: (6, 6) - Valid: True, Latency: 3533ms, Confidence: 0.90
2025-11-03 20:47:40,685 - GUI - INFO - Move 14: (6, 6) - Valid
2025-11-03 20:47:41,695 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:47:41,695 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:47:41,696 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:47:43,747 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:47:43,748 - llm_manager - INFO - Ollama response length: 162 chars
2025-11-03 20:47:43,749 - llm_manager - INFO - Parsed move: (6, 5)
2025-11-03 20:47:43,750 - metrics - INFO - Move 15: (6, 5) - Valid: True, Latency: 2054ms, Confidence: 0.90
2025-11-03 20:47:43,750 - GUI - INFO - Move 15: (6, 5) - Valid
2025-11-03 20:47:44,757 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:47:44,757 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:47:44,758 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:47:49,232 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:47:49,233 - llm_manager - INFO - Ollama response length: 225 chars
2025-11-03 20:47:49,234 - llm_manager - INFO - Parsed move: (6, 4)
2025-11-03 20:47:49,234 - metrics - INFO - Move 16: (6, 4) - Valid: True, Latency: 4478ms, Confidence: 0.90
2025-11-03 20:47:49,235 - GUI - INFO - Move 16: (6, 4) - Valid
2025-11-03 20:47:50,243 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:47:50,244 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:47:50,246 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:47:55,423 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:47:55,427 - llm_manager - INFO - Ollama response length: 350 chars
2025-11-03 20:47:55,428 - llm_manager - INFO - Parsed move: (6, 3)
2025-11-03 20:47:55,429 - metrics - INFO - Move 17: (6, 3) - Valid: True, Latency: 5185ms, Confidence: 0.90
2025-11-03 20:47:55,429 - GUI - INFO - Move 17: (6, 3) - Valid
2025-11-03 20:47:56,440 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:47:56,444 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:47:56,446 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:47:59,880 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:47:59,890 - llm_manager - INFO - Ollama response length: 266 chars
2025-11-03 20:47:59,892 - llm_manager - INFO - Parsed move: (5, 3)
2025-11-03 20:47:59,893 - metrics - INFO - Move 18: (5, 3) - Valid: True, Latency: 3449ms, Confidence: 0.90
2025-11-03 20:47:59,893 - GUI - INFO - Move 18: (5, 3) - Valid
2025-11-03 20:48:00,924 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:48:00,927 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:48:00,927 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:48:05,161 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:48:05,162 - llm_manager - INFO - Ollama response length: 268 chars
2025-11-03 20:48:05,162 - llm_manager - INFO - Parsed move: (4, 3)
2025-11-03 20:48:05,173 - metrics - INFO - Move 19: (4, 3) - Valid: True, Latency: 4246ms, Confidence: 0.90
2025-11-03 20:48:05,173 - GUI - INFO - Move 19: (4, 3) - Valid
2025-11-03 20:48:06,185 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:48:06,186 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:48:06,186 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:48:08,443 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:48:08,454 - llm_manager - INFO - Ollama response length: 208 chars
2025-11-03 20:48:08,455 - llm_manager - INFO - Parsed move: (4, 2)
2025-11-03 20:48:08,456 - metrics - INFO - Move 20: (4, 2) - Valid: True, Latency: 2270ms, Confidence: 0.90
2025-11-03 20:48:08,457 - GUI - INFO - Move 20: (4, 2) - Valid
2025-11-03 20:48:09,469 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:48:09,470 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:48:09,470 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:48:13,839 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:48:13,841 - llm_manager - INFO - Ollama response length: 239 chars
2025-11-03 20:48:13,842 - llm_manager - INFO - Parsed move: (5, 2)
2025-11-03 20:48:13,842 - metrics - INFO - Move 21: (5, 2) - Valid: True, Latency: 4373ms, Confidence: 0.90
2025-11-03 20:48:13,843 - GUI - INFO - Move 21: (5, 2) - Valid
2025-11-03 20:48:14,871 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:48:14,872 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:48:14,872 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:48:19,687 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:48:19,688 - llm_manager - INFO - Ollama response length: 236 chars
2025-11-03 20:48:19,689 - llm_manager - INFO - Parsed move: (6, 2)
2025-11-03 20:48:19,690 - metrics - INFO - Move 22: (6, 2) - Valid: True, Latency: 4819ms, Confidence: 0.90
2025-11-03 20:48:19,691 - GUI - INFO - Move 22: (6, 2) - Valid
2025-11-03 20:48:20,699 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:48:20,700 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:48:20,700 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:48:28,071 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:48:28,075 - llm_manager - INFO - Ollama response length: 277 chars
2025-11-03 20:48:28,075 - llm_manager - INFO - Parsed move: (7, 2)
2025-11-03 20:48:28,077 - metrics - INFO - Move 23: (7, 2) - Valid: True, Latency: 7377ms, Confidence: 0.90
2025-11-03 20:48:28,088 - GUI - INFO - Move 23: (7, 2) - Valid
2025-11-03 20:48:29,107 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:48:29,108 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:48:29,108 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:48:33,063 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:48:33,065 - llm_manager - INFO - Ollama response length: 226 chars
2025-11-03 20:48:33,066 - llm_manager - INFO - Parsed move: (7, 3)
2025-11-03 20:48:33,067 - metrics - INFO - Move 24: (7, 3) - Valid: True, Latency: 3959ms, Confidence: 0.90
2025-11-03 20:48:33,067 - GUI - INFO - Move 24: (7, 3) - Valid
2025-11-03 20:48:34,101 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:48:34,107 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:48:34,108 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:48:36,548 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:48:36,554 - llm_manager - INFO - Ollama response length: 203 chars
2025-11-03 20:48:36,555 - llm_manager - INFO - Parsed move: (7, 4)
2025-11-03 20:48:36,556 - metrics - INFO - Move 25: (7, 4) - Valid: True, Latency: 2450ms, Confidence: 0.90
2025-11-03 20:48:36,557 - GUI - INFO - Move 25: (7, 4) - Valid
2025-11-03 20:48:37,569 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:48:37,574 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:48:37,574 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:48:40,276 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:48:40,280 - llm_manager - INFO - Ollama response length: 185 chars
2025-11-03 20:48:40,280 - llm_manager - INFO - Parsed move: (7, 5)
2025-11-03 20:48:40,281 - metrics - INFO - Move 26: (7, 5) - Valid: True, Latency: 2706ms, Confidence: 0.90
2025-11-03 20:48:40,281 - GUI - INFO - Move 26: (7, 5) - Valid
2025-11-03 20:48:41,317 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:48:41,317 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:48:41,317 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:48:47,639 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:48:47,640 - llm_manager - INFO - Ollama response length: 122 chars
2025-11-03 20:48:47,640 - llm_manager - WARNING - Error accessing JSON fields: 'NoneType' object is not subscriptable
2025-11-03 20:48:47,641 - GUI - WARNING - No move from LLM (stuck: 1/3)
2025-11-03 20:48:48,677 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:48:48,682 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:48:48,683 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:48:51,242 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:48:51,243 - llm_manager - INFO - Ollama response length: 130 chars
2025-11-03 20:48:51,243 - llm_manager - WARNING - Error accessing JSON fields: 'NoneType' object is not subscriptable
2025-11-03 20:48:51,244 - GUI - WARNING - No move from LLM (stuck: 2/3)
2025-11-03 20:48:52,278 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:48:52,283 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:48:52,285 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:48:56,253 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:48:56,254 - llm_manager - INFO - Ollama response length: 150 chars
2025-11-03 20:48:56,256 - llm_manager - WARNING - Error accessing JSON fields: 'NoneType' object is not subscriptable
2025-11-03 20:48:56,271 - GUI - WARNING - No move from LLM (stuck: 3/3)
2025-11-03 20:48:57,284 - metrics - INFO - Game ended - Success: False, Time: 141.0s
2025-11-03 20:48:57,285 - metrics - INFO - Metrics logged to wandb successfully
2025-11-03 20:48:57,296 - GUI - INFO - Game ended

=== GAME SUMMARY ===
Board Size: 8x8
Total Moves: 26
Completion: FAILED âœ—
Time: 141.0s

=== METRICS ===
Valid Moves: 26/26
Bad Moves: 0
Clue Hits: 4
Move Efficiency: 100.0%
Clue Accuracy: 400.0%
Avg Latency: 3797ms
Success Ratio: 0.0%
