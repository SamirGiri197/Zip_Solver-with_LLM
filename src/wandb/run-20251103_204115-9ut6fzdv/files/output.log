2025-11-03 20:41:19,733 - llm_manager - INFO - wandb initialized successfully
2025-11-03 20:41:19,734 - metrics - INFO - Game metrics started for 5x5 board
2025-11-03 20:41:19,735 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:41:19,735 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:41:19,736 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:41:25,904 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:41:25,906 - llm_manager - INFO - Ollama response length: 221 chars
2025-11-03 20:41:25,908 - llm_manager - INFO - Parsed move: (3, 0)
2025-11-03 20:41:25,909 - metrics - INFO - Move 1: (3, 0) - Valid: True, Latency: 6173ms, Confidence: 0.90
2025-11-03 20:41:25,910 - GUI - INFO - Move 1: (3, 0) - Valid
2025-11-03 20:41:26,916 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:41:26,917 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:41:26,918 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:41:34,969 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:41:34,969 - llm_manager - INFO - Ollama response length: 168 chars
2025-11-03 20:41:34,971 - llm_manager - INFO - Parsed move: (3, 1)
2025-11-03 20:41:34,971 - metrics - INFO - Move 2: (3, 1) - Valid: True, Latency: 8055ms, Confidence: 0.90
2025-11-03 20:41:34,971 - GUI - INFO - Move 2: (3, 1) - Valid
2025-11-03 20:41:35,964 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:41:35,965 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:41:35,967 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:41:38,525 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:41:38,526 - llm_manager - INFO - Ollama response length: 215 chars
2025-11-03 20:41:38,528 - llm_manager - INFO - Parsed move: (3, 2)
2025-11-03 20:41:38,529 - metrics - INFO - Move 3: (3, 2) - Valid: True, Latency: 2564ms, Confidence: 0.90
2025-11-03 20:41:38,530 - GUI - INFO - Move 3: (3, 2) - Valid
2025-11-03 20:41:39,538 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:41:39,539 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:41:39,541 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:41:50,721 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:41:50,722 - llm_manager - INFO - Ollama response length: 248 chars
2025-11-03 20:41:50,723 - llm_manager - INFO - Parsed move: (3, 3)
2025-11-03 20:41:50,723 - metrics - INFO - Move 4: (3, 3) - Valid: True, Latency: 11184ms, Confidence: 0.90
2025-11-03 20:41:50,723 - GUI - INFO - Move 4: (3, 3) - Valid
2025-11-03 20:41:51,720 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:41:51,720 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:41:51,721 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:41:57,545 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:41:57,548 - llm_manager - INFO - Ollama response length: 287 chars
2025-11-03 20:41:57,549 - llm_manager - INFO - Parsed move: (2, 3)
2025-11-03 20:41:57,549 - metrics - INFO - Move 5: (2, 3) - Valid: True, Latency: 5830ms, Confidence: 0.90
2025-11-03 20:41:57,551 - GUI - INFO - Move 5: (2, 3) - Valid
2025-11-03 20:41:58,557 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:41:58,557 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:41:58,558 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:42:04,481 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:42:04,482 - llm_manager - INFO - Ollama response length: 350 chars
2025-11-03 20:42:04,483 - llm_manager - INFO - Parsed move: (2, 2)
2025-11-03 20:42:04,484 - metrics - INFO - Move 6: (2, 2) - Valid: True, Latency: 5927ms, Confidence: 0.90
2025-11-03 20:42:04,485 - GUI - INFO - Move 6: (2, 2) - Valid
2025-11-03 20:42:05,476 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:42:05,476 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:42:05,477 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:42:09,348 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:42:09,349 - llm_manager - INFO - Ollama response length: 241 chars
2025-11-03 20:42:09,349 - llm_manager - INFO - Parsed move: (2, 1)
2025-11-03 20:42:09,350 - metrics - INFO - Move 7: (2, 1) - Valid: True, Latency: 3874ms, Confidence: 0.90
2025-11-03 20:42:09,351 - GUI - INFO - Move 7: (2, 1) - Valid
2025-11-03 20:42:10,361 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:42:10,363 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:42:10,363 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:42:15,220 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:42:15,221 - llm_manager - INFO - Ollama response length: 225 chars
2025-11-03 20:42:15,232 - llm_manager - INFO - Parsed move: (1, 1)
2025-11-03 20:42:15,233 - metrics - INFO - Move 8: (1, 1) - Valid: True, Latency: 4870ms, Confidence: 0.90
2025-11-03 20:42:15,234 - GUI - INFO - Move 8: (1, 1) - Valid
2025-11-03 20:42:16,243 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:42:16,244 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:42:16,244 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:42:38,837 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:42:38,838 - llm_manager - INFO - Ollama response length: 290 chars
2025-11-03 20:42:38,838 - llm_manager - INFO - Parsed move: (0, 1)
2025-11-03 20:42:38,838 - metrics - INFO - Move 9: (0, 1) - Valid: True, Latency: 22594ms, Confidence: 0.90
2025-11-03 20:42:38,839 - GUI - INFO - Move 9: (0, 1) - Valid
2025-11-03 20:42:39,845 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:42:39,845 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:42:39,846 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:42:45,229 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:42:45,231 - llm_manager - INFO - Ollama response length: 215 chars
2025-11-03 20:42:45,232 - llm_manager - INFO - Parsed move: (0, 0)
2025-11-03 20:42:45,242 - metrics - INFO - Move 10: (0, 0) - Valid: True, Latency: 5396ms, Confidence: 0.90
2025-11-03 20:42:45,243 - GUI - INFO - Move 10: (0, 0) - Valid
2025-11-03 20:42:46,250 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:42:46,251 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:42:46,251 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:42:48,346 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:42:48,347 - llm_manager - INFO - Ollama response length: 196 chars
2025-11-03 20:42:48,348 - llm_manager - INFO - Parsed move: (1, 0)
2025-11-03 20:42:48,349 - metrics - INFO - Move 11: (1, 0) - Valid: True, Latency: 2098ms, Confidence: 0.90
2025-11-03 20:42:48,349 - GUI - INFO - Move 11: (1, 0) - Valid
2025-11-03 20:42:49,355 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:42:49,356 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:42:49,357 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:42:51,809 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:42:51,810 - llm_manager - INFO - Ollama response length: 173 chars
2025-11-03 20:42:51,810 - llm_manager - INFO - Parsed move: (2, 0)
2025-11-03 20:42:51,811 - metrics - INFO - Move 12: (2, 0) - Valid: True, Latency: 2455ms, Confidence: 0.90
2025-11-03 20:42:51,812 - GUI - INFO - Move 12: (2, 0) - Valid
2025-11-03 20:42:52,818 - llm_manager - INFO - LLM provider set to: ollama (model: gpt-oss:120b-cloud)
2025-11-03 20:42:52,819 - llm_manager - INFO - Starting LLM solve with provider: ollama
2025-11-03 20:42:52,820 - llm_manager - INFO - Calling Ollama with model: gpt-oss:120b-cloud
2025-11-03 20:42:55,271 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-03 20:42:55,285 - llm_manager - INFO - Ollama response length: 122 chars
2025-11-03 20:42:55,287 - llm_manager - ERROR - Error calling Ollama: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "C:\Users\thame\Desktop\CS5900\Zip-game\llm_manager.py", line 255, in solve_with_ollama
    logger.info(f"Parsed move: ({result['next_move']['row']}, {result['next_move']['col']})")
                                 ~~~~~~~~~~~~~~~~~~~^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2025-11-03 20:42:55,297 - GUI - WARNING - No move from LLM
2025-11-03 20:42:55,297 - metrics - INFO - Game ended - Success: False, Time: 95.6s
2025-11-03 20:42:55,298 - metrics - INFO - Metrics logged to wandb successfully
2025-11-03 20:42:55,298 - GUI - INFO - Game ended

=== GAME SUMMARY ===
Board Size: 5x5
Total Moves: 12
Completion: FAILED âœ—
Time: 95.6s

=== METRICS ===
Valid Moves: 12/12
Bad Moves: 0
Clue Hits: 2
Move Efficiency: 100.0%
Clue Accuracy: 66.7%
Avg Latency: 6752ms
Success Ratio: 0.0%
